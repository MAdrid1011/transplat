#!/usr/bin/env python3
"""
é«˜æ–¯åŸºå…ƒ K-NN ç¦»æ•£åº¦åˆ†æè„šæœ¬ (K-Nearest Neighbor Gaussian Dispersion)

åˆ†æ Encoder ç”Ÿæˆçš„é«˜æ–¯åŸºå…ƒåœ¨ 3D ç©ºé—´ä¸­çš„å±€éƒ¨ç¦»æ•£ç¨‹åº¦ï¼Œç”Ÿæˆçƒ­åŠ›å›¾ï¼š
- çº¢è‰²åŒºåŸŸï¼šç¦»æ•£åº¦é«˜ï¼Œé«˜æ–¯å·®å¼‚å¤§ï¼Œéœ€è¦ä¿ç•™ç»†èŠ‚ï¼ˆå°èŒƒå›´åˆå¹¶ï¼‰
- è“è‰²åŒºåŸŸï¼šç¦»æ•£åº¦ä½ï¼Œé«˜æ–¯ç›¸ä¼¼ï¼Œå¯ä»¥å¤§è§„æ¨¡åˆå¹¶

K-NN Gaussian Dispersion å®šä¹‰ï¼š
  å¯¹æ¯ä¸ªé«˜æ–¯ï¼Œè®¡ç®—å…¶ä¸ K ä¸ªæœ€è¿‘é‚»é«˜æ–¯åœ¨ä½ç½®ã€å½¢çŠ¶ã€é¢œè‰²ã€ä¸é€æ˜åº¦ä¸Šçš„ç»¼åˆå·®å¼‚

ä½¿ç”¨æ–¹æ³•:
    é€šè¿‡ run_all_timing_tests.sh è°ƒç”¨:
    bash scripts/run_all_timing_tests.sh transplat --analyze-smoothness
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import torch
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.colors as mcolors


@dataclass
class SmoothnessStats:
    """å•ä¸ªåœºæ™¯çš„å¹³æ»‘åº¦ç»Ÿè®¡"""
    scene_name: str
    total_gaussians: int
    n_views: int
    height: int
    width: int
    
    # å˜åŒ–åº¦ç»Ÿè®¡
    variability_mean: float
    variability_std: float
    variability_min: float
    variability_max: float
    
    # åˆ†å±‚ç»Ÿè®¡
    smooth_ratio: float      # å¹³æ»‘åŒºåŸŸæ¯”ä¾‹ (å˜åŒ–åº¦ < 0.2)
    medium_ratio: float      # ä¸­ç­‰åŒºåŸŸæ¯”ä¾‹ (0.2 <= å˜åŒ–åº¦ < 0.5)
    complex_ratio: float     # å¤æ‚åŒºåŸŸæ¯”ä¾‹ (å˜åŒ–åº¦ >= 0.5)
    
    # åˆå¹¶æ½œåŠ›ä¼°ç®—
    smooth_merge_potential: float   # å¹³æ»‘åŒºåŸŸåˆå¹¶æ½œåŠ› (å¯åˆå¹¶ ~80%)
    medium_merge_potential: float   # ä¸­ç­‰åŒºåŸŸåˆå¹¶æ½œåŠ› (å¯åˆå¹¶ ~50%)
    complex_merge_potential: float  # å¤æ‚åŒºåŸŸåˆå¹¶æ½œåŠ› (å¯åˆå¹¶ ~20%)
    total_merge_potential: float    # æ€»ä½“åˆå¹¶æ½œåŠ›


class GaussianSmoothnessAnalyzer:
    """é«˜æ–¯åŸºå…ƒç©ºé—´å˜åŒ–åº¦åˆ†æå™¨"""
    
    def __init__(self, output_dir: str = "outputs/smoothness_analysis"):
        self.scene_stats: List[SmoothnessStats] = []
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ç”¨äºå¯è§†åŒ–çš„æ•°æ®
        self.last_positions = None
        self.last_variability = None
        self.last_scene_name = None
        
        # ç»Ÿä¸€ 3D é«˜æ–¯åœºçš„æ•°æ®
        self.last_all_positions = None  # [N, 3] æ‰€æœ‰é«˜æ–¯çš„ 3D ä½ç½®
        self.last_3d_variability = None  # [N] æ¯ä¸ªé«˜æ–¯åœ¨ 3D ç©ºé—´ä¸­çš„å˜åŒ–åº¦
    
    def compute_local_variability(self, gaussians, kernel_size: int = 3) -> torch.Tensor:
        """
        è®¡ç®—æ¯ä¸ªé«˜æ–¯çš„å±€éƒ¨å˜åŒ–åº¦
        
        å˜åŒ–åº¦ = è¯¥é«˜æ–¯ä¸å…¶é‚»å±…åœ¨æ‰€æœ‰ç»´åº¦ä¸Šçš„ç»¼åˆå·®å¼‚
        """
        means = gaussians.means[0]  # [N, 3]
        covariances = gaussians.covariances[0]  # [N, 3, 3]
        opacities = gaussians.opacities[0]  # [N]
        harmonics = gaussians.harmonics[0]  # [N, 3, K]
        
        N = means.shape[0]
        # æ¨æ–­å¸ƒå±€
        n_views = 2
        pixels_per_view = N // n_views
        H = W = int(np.sqrt(pixels_per_view))
        
        # é‡å¡‘ä¸º 2D ç½‘æ ¼
        means_2d = means.view(n_views, H, W, 3)
        cov_2d = covariances.view(n_views, H, W, 3, 3)
        op_2d = opacities.view(n_views, H, W)
        sh_2d = harmonics.view(n_views, H, W, harmonics.shape[1], harmonics.shape[2])
        
        # è®¡ç®—å°ºåº¦ç”¨äºå½’ä¸€åŒ–
        scene_scale = means.std()
        cov_scale = covariances.norm(dim=(-2,-1)).mean()
        sh_scale = harmonics.norm(dim=(-2,-1)).mean()
        
        # åˆå§‹åŒ–å˜åŒ–åº¦å¼ é‡
        variability = torch.zeros(n_views, H, W, device=means.device)
        
        # ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—å±€éƒ¨å˜åŒ–åº¦
        pad = kernel_size // 2
        
        for v in range(n_views):
            for i in range(H):
                for j in range(W):
                    # è·å–é‚»åŸŸèŒƒå›´
                    i_min, i_max = max(0, i - pad), min(H, i + pad + 1)
                    j_min, j_max = max(0, j - pad), min(W, j + pad + 1)
                    
                    # å½“å‰é«˜æ–¯
                    curr_pos = means_2d[v, i, j]
                    curr_cov = cov_2d[v, i, j]
                    curr_op = op_2d[v, i, j]
                    curr_sh = sh_2d[v, i, j]
                    
                    # é‚»åŸŸé«˜æ–¯
                    neighbor_pos = means_2d[v, i_min:i_max, j_min:j_max]
                    neighbor_cov = cov_2d[v, i_min:i_max, j_min:j_max]
                    neighbor_op = op_2d[v, i_min:i_max, j_min:j_max]
                    neighbor_sh = sh_2d[v, i_min:i_max, j_min:j_max]
                    
                    # è®¡ç®—ä¸é‚»å±…çš„å·®å¼‚
                    pos_diff = (neighbor_pos - curr_pos).norm(dim=-1) / scene_scale
                    cov_diff = (neighbor_cov - curr_cov).norm(dim=(-2,-1)) / cov_scale
                    op_diff = (neighbor_op - curr_op).abs()
                    sh_diff = (neighbor_sh - curr_sh).norm(dim=(-2,-1)) / sh_scale
                    
                    # ç»¼åˆå˜åŒ–åº¦ (åŠ æƒå¹³å‡)
                    local_var = (
                        0.4 * pos_diff.mean() +  # ä½ç½®æƒé‡æœ€é«˜
                        0.2 * cov_diff.mean() +
                        0.2 * op_diff.mean() +
                        0.2 * sh_diff.mean()
                    )
                    
                    variability[v, i, j] = local_var
        
        return variability, (n_views, H, W)
    
    def compute_local_variability_fast(self, gaussians) -> Tuple[torch.Tensor, Tuple[int, int, int]]:
        """
        å¿«é€Ÿè®¡ç®—å±€éƒ¨å˜åŒ–åº¦ (ä½¿ç”¨å·ç§¯)
        """
        means = gaussians.means[0]
        covariances = gaussians.covariances[0]
        opacities = gaussians.opacities[0]
        harmonics = gaussians.harmonics[0]
        
        N = means.shape[0]
        n_views = 2
        pixels_per_view = N // n_views
        H = W = int(np.sqrt(pixels_per_view))
        
        # é‡å¡‘
        means_2d = means.view(n_views, H, W, 3)
        cov_2d = covariances.view(n_views, H, W, 3, 3)
        op_2d = opacities.view(n_views, H, W)
        sh_2d = harmonics.view(n_views, H, W, harmonics.shape[1], harmonics.shape[2])
        
        # å°ºåº¦
        scene_scale = means.std() + 1e-6
        cov_scale = covariances.norm(dim=(-2,-1)).mean() + 1e-6
        sh_scale = harmonics.norm(dim=(-2,-1)).mean() + 1e-6
        
        variability = torch.zeros(n_views, H, W, device=means.device)
        
        for v in range(n_views):
            # ä½ç½®å˜åŒ–åº¦ï¼šä¸4é‚»åŸŸçš„å·®å¼‚
            pos = means_2d[v]  # [H, W, 3]
            
            # æ°´å¹³å·®å¼‚
            h_diff = torch.zeros_like(pos[:, :, 0])
            h_diff[:, :-1] += (pos[:, 1:] - pos[:, :-1]).norm(dim=-1)
            h_diff[:, 1:] += (pos[:, :-1] - pos[:, 1:]).norm(dim=-1)
            
            # å‚ç›´å·®å¼‚
            v_diff = torch.zeros_like(pos[:, :, 0])
            v_diff[:-1, :] += (pos[1:, :] - pos[:-1, :]).norm(dim=-1)
            v_diff[1:, :] += (pos[:-1, :] - pos[1:, :]).norm(dim=-1)
            
            pos_var = (h_diff + v_diff) / 4 / scene_scale
            
            # åæ–¹å·®å˜åŒ–åº¦
            cov = cov_2d[v]  # [H, W, 3, 3]
            h_cov_diff = torch.zeros(H, W, device=means.device)
            h_cov_diff[:, :-1] += (cov[:, 1:] - cov[:, :-1]).norm(dim=(-2,-1))
            h_cov_diff[:, 1:] += (cov[:, :-1] - cov[:, 1:]).norm(dim=(-2,-1))
            
            v_cov_diff = torch.zeros(H, W, device=means.device)
            v_cov_diff[:-1, :] += (cov[1:, :] - cov[:-1, :]).norm(dim=(-2,-1))
            v_cov_diff[1:, :] += (cov[:-1, :] - cov[1:, :]).norm(dim=(-2,-1))
            
            cov_var = (h_cov_diff + v_cov_diff) / 4 / cov_scale
            
            # Opacity å˜åŒ–åº¦
            op = op_2d[v]
            h_op_diff = torch.zeros(H, W, device=means.device)
            h_op_diff[:, :-1] += (op[:, 1:] - op[:, :-1]).abs()
            h_op_diff[:, 1:] += (op[:, :-1] - op[:, 1:]).abs()
            
            v_op_diff = torch.zeros(H, W, device=means.device)
            v_op_diff[:-1, :] += (op[1:, :] - op[:-1, :]).abs()
            v_op_diff[1:, :] += (op[:-1, :] - op[1:, :]).abs()
            
            op_var = (h_op_diff + v_op_diff) / 4
            
            # SH å˜åŒ–åº¦
            sh = sh_2d[v]
            h_sh_diff = torch.zeros(H, W, device=means.device)
            h_sh_diff[:, :-1] += (sh[:, 1:] - sh[:, :-1]).norm(dim=(-2,-1))
            h_sh_diff[:, 1:] += (sh[:, :-1] - sh[:, 1:]).norm(dim=(-2,-1))
            
            v_sh_diff = torch.zeros(H, W, device=means.device)
            v_sh_diff[:-1, :] += (sh[1:, :] - sh[:-1, :]).norm(dim=(-2,-1))
            v_sh_diff[1:, :] += (sh[:-1, :] - sh[1:, :]).norm(dim=(-2,-1))
            
            sh_var = (h_sh_diff + v_sh_diff) / 4 / sh_scale
            
            # ç»¼åˆå˜åŒ–åº¦
            variability[v] = 0.4 * pos_var + 0.2 * cov_var + 0.2 * op_var + 0.2 * sh_var
        
        return variability, (n_views, H, W), means_2d
    
    def compute_3d_variability(self, gaussians, k_neighbors: int = 8) -> torch.Tensor:
        """
        è®¡ç®—ç»Ÿä¸€ 3D é«˜æ–¯åœºä¸­æ¯ä¸ªé«˜æ–¯çš„å˜åŒ–åº¦
        ä½¿ç”¨ K è¿‘é‚»æ¥è®¡ç®—æ¯ä¸ªé«˜æ–¯ä¸å…¶ 3D ç©ºé—´é‚»å±…çš„å·®å¼‚
        """
        means = gaussians.means[0]  # [N, 3]
        covariances = gaussians.covariances[0]  # [N, 3, 3]
        opacities = gaussians.opacities[0]  # [N]
        harmonics = gaussians.harmonics[0]  # [N, 3, K]
        
        N = means.shape[0]
        device = means.device
        
        # å°ºåº¦
        scene_scale = means.std() + 1e-6
        cov_scale = covariances.norm(dim=(-2,-1)).mean() + 1e-6
        sh_scale = harmonics.norm(dim=(-2,-1)).mean() + 1e-6
        
        # ä½¿ç”¨ç®€å•çš„ç½‘æ ¼åŒ–æ–¹æ³•æ‰¾é‚»å±…ï¼ˆé¿å… KNN çš„è®¡ç®—å¼€é”€ï¼‰
        # å°† 3D ç©ºé—´åˆ’åˆ†ä¸ºç½‘æ ¼ï¼Œæ¯ä¸ªé«˜æ–¯ä¸åŒç½‘æ ¼/ç›¸é‚»ç½‘æ ¼çš„é«˜æ–¯æ¯”è¾ƒ
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šéšæœºé‡‡æ ·é‚»å±…è¿›è¡Œæ¯”è¾ƒ
        variability = torch.zeros(N, device=device)
        
        # ä¸ºäº†æ•ˆç‡ï¼Œä½¿ç”¨æ‰¹é‡è·ç¦»è®¡ç®—
        # å¯¹æ¯ä¸ªé«˜æ–¯ï¼Œéšæœºé‡‡æ · k_neighbors ä¸ªå…¶ä»–é«˜æ–¯ä½œä¸º"ä¼ªé‚»å±…"
        # ç„¶åè®¡ç®—ä¸æœ€è¿‘çš„å‡ ä¸ªçš„å·®å¼‚
        
        batch_size = 4096
        for start in range(0, N, batch_size):
            end = min(start + batch_size, N)
            batch_means = means[start:end]  # [B, 3]
            batch_cov = covariances[start:end]  # [B, 3, 3]
            batch_op = opacities[start:end]  # [B]
            batch_sh = harmonics[start:end]  # [B, 3, K]
            
            # è®¡ç®—ä¸æ‰€æœ‰å…¶ä»–é«˜æ–¯çš„è·ç¦»ï¼ˆé‡‡æ ·ï¼‰
            sample_size = min(1000, N)
            sample_idx = torch.randperm(N, device=device)[:sample_size]
            sample_means = means[sample_idx]  # [S, 3]
            sample_cov = covariances[sample_idx]
            sample_op = opacities[sample_idx]
            sample_sh = harmonics[sample_idx]
            
            # è®¡ç®—è·ç¦» [B, S]
            dist = torch.cdist(batch_means, sample_means)
            
            # æ‰¾åˆ° k ä¸ªæœ€è¿‘é‚»ï¼ˆæ’é™¤è‡ªå·±ï¼‰
            _, nearest_idx = dist.topk(k_neighbors + 1, dim=1, largest=False)
            nearest_idx = nearest_idx[:, 1:]  # æ’é™¤è‡ªå·±ï¼Œ[B, k]
            
            # è®¡ç®—ä¸æœ€è¿‘é‚»çš„å·®å¼‚
            B = end - start
            for i in range(B):
                nn_idx = nearest_idx[i]  # [k]
                
                # ä½ç½®å·®å¼‚
                pos_diff = (sample_means[nn_idx] - batch_means[i]).norm(dim=-1).mean() / scene_scale
                
                # åæ–¹å·®å·®å¼‚
                cov_diff = (sample_cov[nn_idx] - batch_cov[i]).norm(dim=(-2,-1)).mean() / cov_scale
                
                # Opacity å·®å¼‚
                op_diff = (sample_op[nn_idx] - batch_op[i]).abs().mean()
                
                # SH å·®å¼‚
                sh_diff = (sample_sh[nn_idx] - batch_sh[i]).norm(dim=(-2,-1)).mean() / sh_scale
                
                # ç»¼åˆå˜åŒ–åº¦
                variability[start + i] = 0.4 * pos_diff + 0.2 * cov_diff + 0.2 * op_diff + 0.2 * sh_diff
        
        return variability
    
    def analyze_scene(self, scene_name: str, gaussians) -> SmoothnessStats:
        """åˆ†æå•ä¸ªåœºæ™¯çš„é«˜æ–¯å¹³æ»‘åº¦"""
        
        variability, (n_views, H, W), means_2d = self.compute_local_variability_fast(gaussians)
        
        # è®¡ç®—ç»Ÿä¸€ 3D ç©ºé—´çš„å˜åŒ–åº¦
        variability_3d = self.compute_3d_variability(gaussians, k_neighbors=8)
        
        # ä¿å­˜ç”¨äº 2D å¯è§†åŒ–
        self.last_positions = means_2d.cpu()
        self.last_variability = variability.cpu()
        self.last_scene_name = scene_name
        
        # ä¿å­˜ç”¨äº 3D å¯è§†åŒ–ï¼ˆç»Ÿä¸€é«˜æ–¯åœºï¼‰
        self.last_all_positions = gaussians.means[0]  # [N, 3]
        self.last_3d_variability = variability_3d  # [N]
        
        # ç»Ÿè®¡
        var_flat = variability.flatten()
        
        # åˆ†å±‚é˜ˆå€¼
        smooth_thresh = 0.05
        medium_thresh = 0.15
        
        smooth_mask = var_flat < smooth_thresh
        medium_mask = (var_flat >= smooth_thresh) & (var_flat < medium_thresh)
        complex_mask = var_flat >= medium_thresh
        
        smooth_ratio = smooth_mask.float().mean().item()
        medium_ratio = medium_mask.float().mean().item()
        complex_ratio = complex_mask.float().mean().item()
        
        # åˆå¹¶æ½œåŠ›ä¼°ç®—
        # å¹³æ»‘åŒºåŸŸï¼š80% å¯åˆå¹¶ï¼ˆå¤§èŒƒå›´åˆå¹¶ï¼‰
        # ä¸­ç­‰åŒºåŸŸï¼š50% å¯åˆå¹¶ï¼ˆä¸­ç­‰èŒƒå›´åˆå¹¶ï¼‰
        # å¤æ‚åŒºåŸŸï¼š20% å¯åˆå¹¶ï¼ˆå°èŒƒå›´åˆå¹¶ï¼‰
        smooth_merge = smooth_ratio * 0.8
        medium_merge = medium_ratio * 0.5
        complex_merge = complex_ratio * 0.2
        total_merge = smooth_merge + medium_merge + complex_merge
        
        stats = SmoothnessStats(
            scene_name=scene_name,
            total_gaussians=gaussians.means.shape[1],
            n_views=n_views,
            height=H,
            width=W,
            variability_mean=var_flat.mean().item(),
            variability_std=var_flat.std().item(),
            variability_min=var_flat.min().item(),
            variability_max=var_flat.max().item(),
            smooth_ratio=smooth_ratio,
            medium_ratio=medium_ratio,
            complex_ratio=complex_ratio,
            smooth_merge_potential=smooth_merge,
            medium_merge_potential=medium_merge,
            complex_merge_potential=complex_merge,
            total_merge_potential=total_merge,
        )
        
        self.scene_stats.append(stats)
        return stats
    
    def generate_heatmap_2d(self, stats: SmoothnessStats, save_path: Optional[Path] = None):
        """ç”Ÿæˆ 2D å˜åŒ–åº¦çƒ­åŠ›å›¾"""
        if self.last_variability is None:
            return
        
        variability = self.last_variability.numpy()
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        for v in range(variability.shape[0]):
            ax = axes[v]
            im = ax.imshow(variability[v], cmap='RdYlBu_r', vmin=0, vmax=0.3)
            ax.set_title(f'View {v+1} - Gaussian Variability\n(Red=Complex, Blue=Smooth)')
            ax.set_xlabel('Width')
            ax.set_ylabel('Height')
            plt.colorbar(im, ax=ax, label='Variability')
        
        plt.suptitle(f'Scene: {stats.scene_name}\n'
                     f'Smooth: {stats.smooth_ratio*100:.1f}% | '
                     f'Medium: {stats.medium_ratio*100:.1f}% | '
                     f'Complex: {stats.complex_ratio*100:.1f}%')
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.output_dir / f"{stats.scene_name}_heatmap_2d.png"
        plt.savefig(save_path, dpi=150)
        plt.close()
        
        print(f"  2D çƒ­åŠ›å›¾å·²ä¿å­˜: {save_path}")
    
    def generate_heatmap_3d(self, stats: SmoothnessStats, save_path: Optional[Path] = None,
                           downsample: int = 4, percentile_clip: float = 2.0):
        """ç”Ÿæˆ 3D å˜åŒ–åº¦çƒ­åŠ›å›¾ (åˆå¹¶æ‰€æœ‰è§†å›¾)
        
        Args:
            percentile_clip: è£å‰ªæ‰ä½ç½®åœ¨ percentile_clip% å’Œ (100-percentile_clip)% ä¹‹å¤–çš„ç‚¹
        """
        if self.last_all_positions is None or self.last_3d_variability is None:
            return
        
        positions = self.last_all_positions.cpu().numpy()  # [N, 3]
        variability = self.last_3d_variability.cpu().numpy()  # [N]
        
        # è¿‡æ»¤ç¦»ç¾¤ç‚¹ï¼šä½¿ç”¨ç™¾åˆ†ä½æ•°è£å‰ª
        x_low, x_high = np.percentile(positions[:, 0], [percentile_clip, 100 - percentile_clip])
        y_low, y_high = np.percentile(positions[:, 1], [percentile_clip, 100 - percentile_clip])
        z_low, z_high = np.percentile(positions[:, 2], [percentile_clip, 100 - percentile_clip])
        
        # åˆ›å»ºæ©ç 
        mask = (
            (positions[:, 0] >= x_low) & (positions[:, 0] <= x_high) &
            (positions[:, 1] >= y_low) & (positions[:, 1] <= y_high) &
            (positions[:, 2] >= z_low) & (positions[:, 2] <= z_high)
        )
        
        positions_filtered = positions[mask]
        variability_filtered = variability[mask]
        
        # ä¸‹é‡‡æ ·
        step = downsample
        pos = positions_filtered[::step]
        var = variability_filtered[::step]
        
        x, y, z = pos[:, 0], pos[:, 1], pos[:, 2]
        
        # å½’ä¸€åŒ–é¢œè‰²
        c_norm = np.clip(var / 0.3, 0, 1)
        
        filtered_ratio = (1 - mask.sum() / len(mask)) * 100
        print(f"  è¿‡æ»¤ç¦»ç¾¤ç‚¹: {filtered_ratio:.1f}% (ä¿ç•™ {percentile_clip:.0f}-{100-percentile_clip:.0f}% èŒƒå›´)")
        
        # åˆ›å»ºå›¾å½¢
        fig = plt.figure(figsize=(14, 10))
        ax = fig.add_subplot(111, projection='3d')
        
        # ä½¿ç”¨ RdYlBu_r: çº¢è‰²=é«˜å˜åŒ–åº¦ï¼Œè“è‰²=ä½å˜åŒ–åº¦
        scatter = ax.scatter(x, y, z, c=c_norm, cmap='RdYlBu_r', 
                            s=3, alpha=0.6, vmin=0, vmax=1)
        
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        ax.set_title(f'Scene: {stats.scene_name}\n'
                     f'K-NN Gaussian Dispersion ({len(pos):,} / {stats.total_gaussians:,} Gaussians)\n'
                     f'Blue=Low Dispersion (Mergeable), Red=High Dispersion (Keep)')
        
        # æ·»åŠ é¢œè‰²æ¡ï¼ˆæ˜¾ç¤º K-NN Gaussian Dispersion æ•°å€¼ï¼‰
        cbar = plt.colorbar(scatter, ax=ax, shrink=0.6, pad=0.1, label='K-NN Gaussian Dispersion')
        cbar.set_ticks([0, 0.167, 0.333, 0.5, 0.667, 0.833, 1.0])
        cbar.set_ticklabels(['0', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30+'])
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        textstr = (f'Smooth: {stats.smooth_ratio*100:.1f}%\n'
                   f'Medium: {stats.medium_ratio*100:.1f}%\n'
                   f'Complex: {stats.complex_ratio*100:.1f}%\n'
                   f'Merge Potential: {stats.total_merge_potential*100:.1f}%')
        props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
        ax.text2D(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,
                  verticalalignment='top', bbox=props)
        
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.output_dir / f"{stats.scene_name}_heatmap_3d.png"
        plt.savefig(save_path, dpi=150)
        plt.close()
        
        print(f"  3D ç»Ÿä¸€é«˜æ–¯åœºçƒ­åŠ›å›¾å·²ä¿å­˜: {save_path}")
    
    def generate_heatmap_3d_multiview(self, stats: SmoothnessStats, save_path: Optional[Path] = None,
                                       downsample: int = 4, percentile_clip: float = 2.0):
        """ç”Ÿæˆå¤šè§’åº¦ 3D çƒ­åŠ›å›¾"""
        if self.last_all_positions is None or self.last_3d_variability is None:
            return
        
        positions = self.last_all_positions.cpu().numpy()
        variability = self.last_3d_variability.cpu().numpy()
        
        # è¿‡æ»¤ç¦»ç¾¤ç‚¹
        x_low, x_high = np.percentile(positions[:, 0], [percentile_clip, 100 - percentile_clip])
        y_low, y_high = np.percentile(positions[:, 1], [percentile_clip, 100 - percentile_clip])
        z_low, z_high = np.percentile(positions[:, 2], [percentile_clip, 100 - percentile_clip])
        
        mask = (
            (positions[:, 0] >= x_low) & (positions[:, 0] <= x_high) &
            (positions[:, 1] >= y_low) & (positions[:, 1] <= y_high) &
            (positions[:, 2] >= z_low) & (positions[:, 2] <= z_high)
        )
        
        positions_filtered = positions[mask]
        variability_filtered = variability[mask]
        
        step = downsample
        pos = positions_filtered[::step]
        var = variability_filtered[::step]
        x, y, z = pos[:, 0], pos[:, 1], pos[:, 2]
        c_norm = np.clip(var / 0.3, 0, 1)
        
        # åˆ›å»º 2x2 å¤šè§’åº¦è§†å›¾
        fig = plt.figure(figsize=(16, 14))
        
        views = [
            (30, 45, 'View 1 (Default)'),
            (30, 135, 'View 2 (Rotated 90Â°)'),
            (60, 45, 'View 3 (Top-down)'),
            (0, 0, 'View 4 (Front)')
        ]
        
        for i, (elev, azim, title) in enumerate(views):
            ax = fig.add_subplot(2, 2, i + 1, projection='3d')
            scatter = ax.scatter(x, y, z, c=c_norm, cmap='RdYlBu_r', 
                                s=2, alpha=0.5, vmin=0, vmax=1)
            ax.view_init(elev=elev, azim=azim)
            ax.set_xlabel('X')
            ax.set_ylabel('Y')
            ax.set_zlabel('Z')
            ax.set_title(title)
        
        plt.suptitle(f'Scene: {stats.scene_name} - K-NN Gaussian Dispersion (Multi-view)\n'
                     f'Total: {stats.total_gaussians:,} | Merge Potential: {stats.total_merge_potential*100:.1f}%',
                     fontsize=14)
        
        # æ·»åŠ é¢œè‰²æ¡ï¼ˆæ˜¾ç¤º K-NN Gaussian Dispersion æ•°å€¼ï¼‰
        cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
        sm = plt.cm.ScalarMappable(cmap='RdYlBu_r', norm=plt.Normalize(0, 1))
        cbar = fig.colorbar(sm, cax=cbar_ax, label='K-NN Dispersion')
        cbar.set_ticks([0, 0.167, 0.333, 0.5, 0.667, 0.833, 1.0])
        cbar.set_ticklabels(['0', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30+'])
        
        plt.tight_layout(rect=[0, 0, 0.9, 0.95])
        
        if save_path is None:
            save_path = self.output_dir / f"{stats.scene_name}_heatmap_3d_multiview.png"
        plt.savefig(save_path, dpi=150)
        plt.close()
        
        print(f"  å¤šè§’åº¦ 3D çƒ­åŠ›å›¾å·²ä¿å­˜: {save_path}")
    
    def print_scene_report(self, stats: SmoothnessStats):
        """æ‰“å°å•ä¸ªåœºæ™¯çš„åˆ†ææŠ¥å‘Š"""
        print(f"\n  ========== é«˜æ–¯å¹³æ»‘åº¦åˆ†æ: {stats.scene_name} ==========")
        print(f"  é«˜æ–¯æ•°: {stats.total_gaussians:,}, åˆ†è¾¨ç‡: {stats.height}x{stats.width}x{stats.n_views}")
        
        print(f"\n  ã€å˜åŒ–åº¦ç»Ÿè®¡ã€‘")
        print(f"    Mean: {stats.variability_mean:.4f}")
        print(f"    Std:  {stats.variability_std:.4f}")
        print(f"    Range: [{stats.variability_min:.4f}, {stats.variability_max:.4f}]")
        
        print(f"\n  ã€åŒºåŸŸåˆ†å¸ƒã€‘")
        print(f"    â”Œ{'â”€'*20}â”¬{'â”€'*15}â”¬{'â”€'*20}â”")
        print(f"    â”‚{'åŒºåŸŸç±»å‹':^20}â”‚{'å æ¯”':^15}â”‚{'åˆå¹¶æ½œåŠ›':^20}â”‚")
        print(f"    â”œ{'â”€'*20}â”¼{'â”€'*15}â”¼{'â”€'*20}â”¤")
        print(f"    â”‚  å¹³æ»‘ (var<0.05)   â”‚{stats.smooth_ratio*100:>12.1f}%  â”‚  ~80% å¯å¤§èŒƒå›´åˆå¹¶  â”‚")
        print(f"    â”‚  ä¸­ç­‰ (0.05-0.15)  â”‚{stats.medium_ratio*100:>12.1f}%  â”‚  ~50% å¯ä¸­èŒƒå›´åˆå¹¶  â”‚")
        print(f"    â”‚  å¤æ‚ (var>=0.15)  â”‚{stats.complex_ratio*100:>12.1f}%  â”‚  ~20% å¯å°èŒƒå›´åˆå¹¶  â”‚")
        print(f"    â””{'â”€'*20}â”´{'â”€'*15}â”´{'â”€'*20}â”˜")
        
        print(f"\n  ã€åˆå¹¶æ½œåŠ›ä¼°ç®—ã€‘")
        print(f"    å¹³æ»‘åŒºåŸŸè´¡çŒ®: {stats.smooth_merge_potential*100:.1f}%")
        print(f"    ä¸­ç­‰åŒºåŸŸè´¡çŒ®: {stats.medium_merge_potential*100:.1f}%")
        print(f"    å¤æ‚åŒºåŸŸè´¡çŒ®: {stats.complex_merge_potential*100:.1f}%")
        print(f"    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"    æ€»ä½“åˆå¹¶æ½œåŠ›: {stats.total_merge_potential*100:.1f}%")
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        self.generate_heatmap_2d(stats)
        self.generate_heatmap_3d(stats)
        self.generate_heatmap_3d_multiview(stats)
    
    def print_summary_report(self, model_name: str):
        """æ‰“å°æ‰€æœ‰åœºæ™¯çš„æ±‡æ€»æŠ¥å‘Š"""
        if not self.scene_stats:
            print("[Warning] No smoothness stats collected")
            return
        
        n_scenes = len(self.scene_stats)
        
        # æ±‡æ€»
        avg_smooth = np.mean([s.smooth_ratio for s in self.scene_stats])
        avg_medium = np.mean([s.medium_ratio for s in self.scene_stats])
        avg_complex = np.mean([s.complex_ratio for s in self.scene_stats])
        avg_merge_potential = np.mean([s.total_merge_potential for s in self.scene_stats])
        
        avg_gaussians = np.mean([s.total_gaussians for s in self.scene_stats])
        total_mb = avg_gaussians * 352 / 1024 / 1024
        
        print("\n" + "=" * 100)
        print(f"  â–ˆâ–ˆâ–ˆ {model_name.upper()} é«˜æ–¯å¹³æ»‘åº¦åˆ†ææ€»ç»“ â–ˆâ–ˆâ–ˆ")
        print("=" * 100)
        
        print(f"\n  ç»Ÿè®¡åœºæ™¯æ•°: {n_scenes}")
        print(f"  å¹³å‡é«˜æ–¯æ•°: {avg_gaussians:,.0f}")
        
        print(f"\n  ã€åŒºåŸŸåˆ†å¸ƒæ±‡æ€»ã€‘")
        print(f"  â”Œ{'â”€'*25}â”¬{'â”€'*15}â”¬{'â”€'*25}â”")
        print(f"  â”‚{'åŒºåŸŸç±»å‹':^25}â”‚{'å¹³å‡å æ¯”':^15}â”‚{'åˆå¹¶ç­–ç•¥':^25}â”‚")
        print(f"  â”œ{'â”€'*25}â”¼{'â”€'*15}â”¼{'â”€'*25}â”¤")
        print(f"  â”‚  ğŸ”µ å¹³æ»‘åŒºåŸŸ (var<0.05)  â”‚{avg_smooth*100:>12.1f}%  â”‚  å¤§èŒƒå›´åˆå¹¶ (4x4+)       â”‚")
        print(f"  â”‚  ğŸŸ¡ ä¸­ç­‰åŒºåŸŸ (0.05-0.15) â”‚{avg_medium*100:>12.1f}%  â”‚  ä¸­èŒƒå›´åˆå¹¶ (2x2)        â”‚")
        print(f"  â”‚  ğŸ”´ å¤æ‚åŒºåŸŸ (var>=0.15) â”‚{avg_complex*100:>12.1f}%  â”‚  å°èŒƒå›´åˆå¹¶ (ç›¸é‚»å¯¹)     â”‚")
        print(f"  â””{'â”€'*25}â”´{'â”€'*15}â”´{'â”€'*25}â”˜")
        
        print(f"\n  ã€HBM èŠ‚çœä¼°ç®—ã€‘")
        print(f"  åŸå§‹æ•°æ®é‡: {total_mb:.2f} MB")
        print(f"  æ€»ä½“åˆå¹¶æ½œåŠ›: {avg_merge_potential*100:.1f}%")
        print(f"  ä¼°ç®—å¯èŠ‚çœ: {total_mb * avg_merge_potential:.2f} MB")
        
        new_count = int(avg_gaussians * (1 - avg_merge_potential))
        print(f"\n  ã€åˆå¹¶å‰åå¯¹æ¯”ã€‘")
        print(f"  åˆå¹¶å‰é«˜æ–¯æ•°: {avg_gaussians:,.0f}")
        print(f"  åˆå¹¶åé«˜æ–¯æ•°: {new_count:,} (å‡å°‘ {avg_merge_potential*100:.1f}%)")
        
        print(f"\n  çƒ­åŠ›å›¾å·²ä¿å­˜è‡³: {self.output_dir}")
        print("=" * 100)
        print()


# å•ä¾‹æ¨¡å¼
_analyzer_instance: Optional[GaussianSmoothnessAnalyzer] = None


def get_smoothness_analyzer() -> GaussianSmoothnessAnalyzer:
    """è·å–å…¨å±€åˆ†æå™¨å®ä¾‹"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = GaussianSmoothnessAnalyzer()
    return _analyzer_instance


def reset_smoothness_analyzer():
    """é‡ç½®åˆ†æå™¨"""
    global _analyzer_instance
    _analyzer_instance = None
