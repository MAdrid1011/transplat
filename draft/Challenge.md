## 可泛化3DGS Encoder加速器设计挑战

### Challenge 1：逐像素独立深度搜索忽视2D特征空间的语义相似性导致计算冗余与高访存开销

在可泛化三维高斯场景重建的深度预测阶段，现有方法普遍采用逐像素独立的密集深度搜索：对于参考图像中的每个像素，系统在 D 个深度假设下将其投影到目标图像，采样对应位置的特征并计算匹配代价，最终选择代价最优的深度作为该像素的估计值。以 TransPlat 为例，在 $64 \times 64$ 的特征图和 32 个深度候选设置下，单次推理需要对 4096 个像素分别执行完整的深度搜索，总计 $4096 \times 32 = 131{,}072$ 次特征匹配运算，逐元素计算计算强度极高。 然而，在二维特征空间中，像素并非孤立存在：特征向量相似的像素往往来自同一物体表面，因此具有相近的深度。这种二维特征空间的语义相似性基于两个先验共识：（i）同一物体表面的相邻像素共享相似的纹理、材质与光照，导致 CNN 提取的特征向量高度相关；（ii）物体表面几何通常平滑，深度在局部区域连续变化。 我们的实测结果进一步量化了这种二维特征空间的语义关联：在 4096 个像素中，特征余弦相似度超过 0.92 的像素对，其深度差异中位数仅为平均深度的 2.3%；而特征相似度低于 0.7 的像素对，深度差异中位数可达 12.7%。这表明，一旦像素 A 与像素 B 在二维特征空间中语义相似，A 的深度搜索结果对 B 具有很强的预测能力。

然而，现有系统难以充分利用二维特征空间中的语义可复用性。根本原因在于：现有实现主要支持地址相似性的复用，但不支持语义相似性的复用。换言之，即使两个像素在二维特征空间中非常接近，系统也无法快速识别这种语义相似性并直接复用已计算的深度先验，而只能按照固定流程对每个像素重复进行同等规模的投影、采样与匹配计算，导致大量冗余计算和访存开销。我们在 Jetson Orin NX（2MB L2Cache）上测得，深度预测阶段的L2缓存命中率仅为31.2%；同时，深度预测阶段产生的L2Cache到HBM的流量在多种模型中几乎占据Encoder60%以上的流量，执行时间占比超过55%。以TransPlat为例，4096个像素的完整深度预测将产生约108GB的HBM流量需求，远远超过Orin NX 68GB/s带宽所能支撑的实时推理预算。

综上所述，现有的深度预测流程存在一个核心矛盾：一方面，像素按顺序处理时，前序像素的深度结果本可以作为后续在二维特征空间中语义相似像素的强先验，从而跳过大部分重复搜索；另一方面，系统缺乏面向二维特征空间语义相似性的机制来识别可复用关系并复用计算结果，导致场景语义结构中蕴含的大量可复用计算和访存结果被浪费，最终表现为不必要的匹配运算和巨大的HBM流量开销。

### Challenge 2：逐像素独立生成高斯忽略了3D几何空间的局部连续性导致 Decoder 冗余访存

传统优化式 3DGS 通过多轮迭代训练，能够自适应地合并相似高斯基元、剪枝低贡献高斯基元，最终收敛到紧凑的场景表示。然而，为了保持对任意新场景的泛化能力，可泛化 3DGS 采用前馈式逐像素生成策略：Encoder 将每个源图像像素独立转换为一个高斯基元，且不进行任何合并与优化。以 TransPlat 为例，$256 \times 256$ 的双视图在 Decoder 渲染阶段产生了 131k 个高斯基元，单场景数据量达到 44.0 MB。作为对比，传统训练式 3DGS 在达到相近渲染质量（PSNR 和 SSIM 差异小于 0.1%）的前提下，同等规模的室内场景通常仅需 40k 个高斯基元，渲染阶段加载的高斯基元数据量仅为 13.5 MB。这意味着可泛化方法在 Decoder 阶段的 HBM 流量相比优化式方法增加了 3.25 倍。

造成上述冗余的根本原因在于：逐像素生成策略完全忽视了三维几何空间的局部连续性。在真实场景中，同一表面的相邻像素具有相近的深度、颜色与材质，其对应的高斯分布在三维几何空间中表现出强烈的局部连续性——位置接近、形状相似、颜色相近。我们通过K近邻高斯离散度（K-NN Gaussian Dispersion）对TransPlat、MVSplat和DepthSplat生成的多个场景高斯场进行了量化分析，结果表明：73.6%的高斯分布处于低离散度区域（K-NN Dispersion < 0.05），其在三维几何空间中4×4邻域内的高斯在位置、协方差、不透明度及球谐系数等各维度上的综合差异极小；仅有7.2%的高斯分布位于高离散度区域（如边缘、遮挡边界等），但与其相邻高斯在基元属性上的差异也很小。换言之，三维几何空间中大量高斯分布与其邻居几乎重叠，在渲染时被重复加载和计算，却对最终图像质量贡献甚微。

综上所述，可泛化 3DGS 的数据流存在一个核心矛盾：一方面，场景在 3D 几何空间中具有强烈的局部连续性，相邻像素生成的高斯分布天然具有可合并性；另一方面，Encoder 的逐像素生成机制无法感知这种 3D 几何空间的局部连续性，只能盲目地为每个像素独立生成一个高斯分布。这导致在 Decoder 阶段，尤其是在边缘设备上，相较于训练式 3DGS，系统被迫加载近 70% 的冗余高斯分布，成为实时渲染的带宽瓶颈。

### 我们的方法

我们提出了 SAGE（Scene-Aware Gaussian Engine），一种面向可泛化 3DGS 的推理加速架构。SAGE 基于二维特征空间的语义相似性与三维几何空间的局部连续性，在编码器中引入了两个核心设计：

#### 深度特征计算缓存（Depth-Feature Computation Cache，DFCC）

针对Challenge 1，在深度预测数据通路中，我们引入了片上语义索引缓存与计算旁路逻辑。当像素特征流入深度搜索单元时，硬件哈希电路会生成其低维语义签名，并以极低延迟查询片上缓存；若命中语义相似条目，旁路逻辑则直接输出缓存中的深度值，并施加基于空间梯度的轻量级修正，从而跳过下游完整的深度搜索通路。与软件缓存策略不同，DFCC 将“语义签名→深度结果”的索引关系固化于数据通路中，将查询延迟从数百周期压缩至单周期，使语义级复用能够在流水线吞吐下稳定生效。

#### 流式高斯合并（Streaming Gaussian Merging，SGM）

针对 Challenge 2，我们在 Encoder 的高斯生成流水线中引入了流式高斯合并（SGM）。由于高斯按照像素光栅扫描顺序逐个生成，SGM 在片上维护行缓存，使当前高斯仅需与缓存中固定位置的邻居进行差异计算。硬件实时计算当前高斯与邻域高斯在位置、协方差和颜色等属性上的归一化差异，得到局部离散度，并据此执行分类合并：在低离散度区域采用大窗口激进合并，在高离散度区域保持高斯独立，以保留几何细节。合并后的高斯在片上完成加权平均后写入 HBM，将合并操作前置到写入源头，从而减少冗余高斯带来的 HBM 往返开销，缓解 Decoder 的访存压力。

